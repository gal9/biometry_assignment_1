{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "from src.data import read_grayscale_image\n",
    "from src.features import flatten_image, LBP\n",
    "from src.recognition import euclidian_distance_recognition, euclidian_distance_recognition_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images_grayscale = []\n",
    "images_flattened = []\n",
    "images_LBP_1_8 = []\n",
    "\n",
    "data_location = \"data/awe\"\n",
    "\n",
    "# Loop through data directory\n",
    "for filename in os.listdir(data_location):\n",
    "    f = os.path.join(data_location, filename)\n",
    "\n",
    "    if os.path.isdir(f):\n",
    "        grayscalles_tmp = []\n",
    "        flattened_tmp = []\n",
    "        LBP_1_8_tmp = []\n",
    "\n",
    "        for image_file in os.listdir(f):\n",
    "            image_location = os.path.join(f, image_file)\n",
    "\n",
    "            if(image_file.endswith(\".png\")):\n",
    "                print(f\"Reading image {image_location}\", end=\"\\r\")\n",
    "\n",
    "                # Reading grayscale image and transforming it to 1D vector\n",
    "                image_grayscale = read_grayscale_image(image_location, 128, 128)\n",
    "                image_flattened = flatten_image(image_grayscale)\n",
    "                LBP_1_8 = flatten_image(LBP(image_grayscale, 1, 8))\n",
    "\n",
    "                grayscalles_tmp.append(image_grayscale)\n",
    "                flattened_tmp.append(image_flattened)\n",
    "                LBP_1_8_tmp.append(LBP_1_8)\n",
    "        \n",
    "        images_LBP_1_8.append(LBP_1_8_tmp)\n",
    "        images_grayscale.append(grayscalles_tmp)\n",
    "        images_flattened.append(flattened_tmp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TP = 0\n",
    "c = 0\n",
    "number_of_people = len(images_flattened)\n",
    "number_of_samples = len(images_flattened)*len(images_flattened[0])\n",
    "\n",
    "for persone_index, samples in enumerate(images_flattened):\n",
    "    #print(f\"Persone {persone_index+1}/{number_of_people}\", end=\"\\r\")\n",
    "    for sample_i, sample in enumerate(samples):\n",
    "        c += 1\n",
    "        print(f\"Sample {c}/{number_of_samples}\", end=\"\\r\")\n",
    "        persone_recognised_i, image_recognised_i = euclidian_distance_recognition_2(sample, images_flattened, persone_index, sample_i)\n",
    "\n",
    "        # Test if image was correctly classfied\n",
    "        if(persone_index==persone_recognised_i):\n",
    "            # print(persone_recognised_i)\n",
    "            TP += 1\n",
    "\n",
    "print()\n",
    "\n",
    "print(TP/number_of_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TP = 0\n",
    "c = 0\n",
    "\n",
    "number_of_people = len(images_LBP_1_8)\n",
    "number_of_samples = len(images_LBP_1_8)*len(images_LBP_1_8[0])\n",
    "\n",
    "for persone_index, samples in enumerate(images_LBP_1_8):\n",
    "    for sample_i, sample in enumerate(samples):\n",
    "        c += 1\n",
    "        print(f\"Sample {c}/{number_of_samples}\", end=\"\\r\")\n",
    "        persone_recognised_i, image_recognised_i = euclidian_distance_recognition_2(sample, images_flattened, persone_index, sample_i)\n",
    "\n",
    "        # Test if image was correctly classfied\n",
    "        if(persone_index==persone_recognised_i):\n",
    "            # print(persone_recognised_i)\n",
    "            TP += 1\n",
    "\n",
    "print()\n",
    "\n",
    "print(TP/number_of_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform_and_show(\"data/awe/001/01.png\", 2, 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "94d5a9fbff655286490b18cbb601f7310f051b7676684e3dc1ee79130cc74a2f"
  },
  "kernelspec": {
   "display_name": "Python 3.9.0 ('biometry')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5c13dbc957bb8477a7893c79680d2a6cafd4dd4044001ad54528252da2651a6e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
